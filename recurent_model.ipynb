{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\soft\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from conv_rmm_cell import ConvCell\n",
    "from data import get_features\n",
    "from utils import plot_confusion_matrix, cross_entropy, accuracy, get_spectogram\n",
    "\n",
    "import librosa\n",
    "\n",
    "from model import get_model\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HARM = 14\n",
    "N_CAND = 100\n",
    "SEQ_LEN = 16\n",
    "N_HIDDEN = 16\n",
    "BATCH_SIZE = 128\n",
    "# N_CLASS = 3\n",
    "\n",
    "START_LR = 0.05\n",
    "TRAINING_STEPS = 500000\n",
    "LR_PERIONS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    filenames = []\n",
    "    for f in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path, f)) and f.endswith('.npz'):\n",
    "            filenames.append(os.path.join(path, f))\n",
    "#             data = np.load(os.path.join(path, f))\n",
    "#             features = data['features']\n",
    "#             if features.shape[0] > SEQ_LEN:\n",
    "#                 filenames.append(os.path.join(path, f))\n",
    "    \n",
    "    return filenames\n",
    "\n",
    "# DATA_PATH = 'C:/Dataset/noisy_speech'\n",
    "DATA_PATH = 'D:/musan/preprocessed/noisy_speech_v2'\n",
    "FOLDERS = ['train', 'valid']\n",
    "\n",
    "train_files = np.array([(filename, True) for filename in get_files(os.path.join(DATA_PATH, FOLDERS[0]))])\n",
    "np.random.shuffle(train_files)\n",
    "\n",
    "valid_files = np.array([(filename, False) for filename in get_files(os.path.join(DATA_PATH, FOLDERS[1]))])\n",
    "np.random.shuffle(valid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std = np.load('mean-std.npz')\n",
    "\n",
    "mean = mean_std['mean'][np.newaxis, np.newaxis, ...]\n",
    "std = mean_std['std'][np.newaxis, np.newaxis, ...]\n",
    "\n",
    "mean = tf.constant(mean, name='mean')\n",
    "std = tf.constant(std, name='std')\n",
    "\n",
    "seq_len_t = tf.constant(SEQ_LEN, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    path = path.decode()\n",
    "    data = np.load(path)\n",
    "    features = data['features']\n",
    "    labels = data['labels'].astype(np.float32)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(features, labels):\n",
    "    stride = SEQ_LEN // 2\n",
    "    n_samples = features.shape[0] // stride  - SEQ_LEN + 1\n",
    "    if n_samples > 0:\n",
    "        batch_features = np.zeros(shape=(n_samples, SEQ_LEN, N_CAND, N_HARM), dtype=np.float32)\n",
    "        batch_targets = np.zeros(shape=(n_samples, SEQ_LEN, 1), dtype=np.float32)\n",
    "\n",
    "        labels = labels[..., np.newaxis]\n",
    "        for i in range(n_samples):\n",
    "            batch_features[i] = features[i * stride:i * stride+SEQ_LEN]\n",
    "            batch_targets[i] = labels[i * stride:i * stride+SEQ_LEN]\n",
    "\n",
    "        return batch_features, batch_targets\n",
    "    else:\n",
    "        batch_features = np.zeros(shape=(1, SEQ_LEN, N_CAND, N_HARM), dtype=np.float32)\n",
    "        batch_targets = np.zeros(shape=(1, SEQ_LEN, 1), dtype=np.float32)\n",
    "        \n",
    "        _features = features[:SEQ_LEN]\n",
    "        _labels = labels[:SEQ_LEN]\n",
    "        batch_features[0, :_features.shape[0]] = _features\n",
    "        batch_targets[:, :_features.shape[0], 0] = _labels\n",
    "        \n",
    "        return batch_features, batch_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dataset'):\n",
    "    filenames = tf.placeholder(dtype=train_files.dtype, name='filename')\n",
    "#     is_speech_phr = tf.placeholder(dtype=tf.bool, name='is_speech')\n",
    "\n",
    "    dataset = tf.data.Dataset().from_tensor_slices((filenames))\n",
    "    dataset = dataset.map(lambda filename: tf.py_func(load_file, [filename], [tf.float32, tf.float32]))\n",
    "    dataset = dataset.cache('C:/Dataset/cache/')\n",
    "    dataset = dataset.map(lambda features, labels: tf.py_func(prepare_data, [features, labels], [tf.float32, tf.float32]), 4)\n",
    "#     dataset = dataset.map(lambda features, labels, length: prepare_data(features, labels, length), 4)\n",
    "    dataset = dataset.flat_map(lambda *samples: tf.data.Dataset().from_tensor_slices(samples))\n",
    "    dataset = dataset.map(lambda features, labels: (tf.reshape(features, [SEQ_LEN, N_CAND, N_HARM]), tf.reshape(labels, [SEQ_LEN, 1])))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(20000)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(buffer_size=1)\n",
    "    \n",
    "    train_iterator = dataset.make_initializable_iterator()\n",
    "    valid_iterator = dataset.make_initializable_iterator()\n",
    "    \n",
    "    train_batch = train_iterator.get_next()\n",
    "    valid_batch = valid_iterator.get_next()\n",
    "    \n",
    "    is_training = tf.placeholder_with_default(True, shape=None, name='is_training')\n",
    "\n",
    "    batch_features, batch_targets = tf.cond(is_training, \n",
    "                                      true_fn=lambda: train_batch, \n",
    "                                      false_fn=lambda: valid_batch)   \n",
    "    batch_features = tf.reshape(batch_features, [-1, SEQ_LEN, N_CAND, N_HARM])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {}\n",
    "model['N_HIDDEN'] = N_HIDDEN\n",
    "model['N_CAND'] = N_CAND\n",
    "model['SEQ_LEN'] = SEQ_LEN\n",
    "model['BATCH_SIZE'] = BATCH_SIZE\n",
    "\n",
    "rnn_predictions, cnn_predictions = get_model(batch_features, model, mean, std, is_training=True, return_activations=False)\n",
    "\n",
    "with tf.name_scope('postprocessing'):\n",
    "    rnn_classes = tf.cast(rnn_predictions > 0.5, tf.int32)\n",
    "    cnn_classes = tf.cast(cnn_predictions > 0.5, tf.int32)\n",
    "    \n",
    "    cnn_targets = tf.reshape(batch_targets, [-1, 1])\n",
    "    cnn_targets = cnn_targets[:, 0]\n",
    "\n",
    "    targets = tf.transpose(batch_targets, [1, 0, 2])\n",
    "    targets = tf.gather(targets, int(targets.get_shape()[0]) - 1, name=\"last_batch_target\")[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_cost = cross_entropy(targets=cnn_targets, predictions=cnn_predictions)\n",
    "cnn_loss = tf.reduce_mean(cnn_cost)\n",
    "\n",
    "output_cost = cross_entropy(targets=targets, predictions=rnn_predictions)\n",
    "output_loss = tf.reduce_mean(output_cost)\n",
    "\n",
    "loss = output_loss + cnn_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\soft\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.Variable(0, dtype=tf.int32)\n",
    "lr_period_steps = int(TRAINING_STEPS / LR_PERIONS)\n",
    "global_step_update_op = tf.cond(global_step < tf.convert_to_tensor(lr_period_steps), \n",
    "                                true_fn=lambda: global_step.assign(global_step + 1),\n",
    "                               false_fn=lambda: global_step.assign(0))\n",
    "\n",
    "lr = tf.train.linear_cosine_decay(START_LR, global_step, lr_period_steps)\n",
    "\n",
    "\n",
    "cnn_trainable_variables = tf.trainable_variables('CNN')\n",
    "cnn_grads = tf.gradients(cnn_loss, cnn_trainable_variables, name='gradients_cnn')\n",
    "cnn_optimizer = tf.train.MomentumOptimizer(lr, momentum=0.9)\n",
    "cnn_train_op = cnn_optimizer.apply_gradients(zip(cnn_grads, cnn_trainable_variables))\n",
    "\n",
    "rnn_trainable_variables = tf.trainable_variables('RNN')\n",
    "rnn_grads = tf.gradients(output_loss, rnn_trainable_variables, name='gradients_rnn')\n",
    "rnn_optimizer = tf.train.MomentumOptimizer(lr, momentum=0.9)\n",
    "rnn_train_op = rnn_optimizer.apply_gradients(zip(rnn_grads, rnn_trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_accuracy = accuracy(cnn_classes, tf.cast(cnn_targets, tf.int32))\n",
    "rnn_accuracy = accuracy(rnn_classes, tf.cast(targets, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cm = tf.confusion_matrix(labels=tf.cast(targets, tf.int32), predictions=rnn_classes, num_classes=2)\n",
    "cnn_cm = tf.confusion_matrix(labels=tf.cast(cnn_targets, tf.int32), predictions=cnn_classes, num_classes=2)\n",
    "\n",
    "def _plot_confusion_matrix_wrapper(confusion_matrix):\n",
    "    return plot_confusion_matrix(confusion_matrix, {'Noise': 0, 'Voice': 1})\n",
    "\n",
    "rnn_confusion_matrix_img = tf.py_func(_plot_confusion_matrix_wrapper, [rnn_cm], tf.uint8)\n",
    "rnn_confusion_matrix_img = tf.expand_dims(rnn_confusion_matrix_img, axis=0)\n",
    "\n",
    "cnn_confusion_matrix_img = tf.py_func(_plot_confusion_matrix_wrapper, [cnn_cm], tf.uint8)\n",
    "cnn_confusion_matrix_img = tf.expand_dims(cnn_confusion_matrix_img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = []\n",
    "\n",
    "for grad in cnn_grads + rnn_grads:\n",
    "    if not ('bias' in grad.name.lower()):\n",
    "        tf.summary.scalar('gradients/'+grad.name, tf.reduce_mean(tf.abs(grad)))\n",
    "        tf.summary.histogram('gradients/'+grad.name, grad)\n",
    "        \n",
    "for param in tf.trainable_variables():\n",
    "    if not ('bias' in param.name.lower()):\n",
    "        tf.summary.histogram('parameters/'+param.name, param)\n",
    "        \n",
    "tf.summary.scalar('learning_rate', lr)\n",
    "summaries.append(tf.summary.scalar('losses/rnn_loss', output_loss))\n",
    "# tf.summary.scalar('losses/l1_loss', l1_loss)\n",
    "summaries.append(tf.summary.scalar('losses/total_loss', loss))\n",
    "summaries.append(tf.summary.scalar('losses/cnn_loss', cnn_loss))\n",
    "summaries.append(tf.summary.scalar('accuracy/rnn', rnn_accuracy))\n",
    "summaries.append(tf.summary.scalar('accuracy/cnn', cnn_accuracy))\n",
    "\n",
    "# tf.summary.audio()\n",
    "\n",
    "summaries.append(tf.summary.image('confusion-matrix/rnn', rnn_confusion_matrix_img))\n",
    "summaries.append(tf.summary.image('confusion-matrix/cnn', cnn_confusion_matrix_img))\n",
    "\n",
    "\n",
    "train_summary_op = tf.summary.merge_all()\n",
    "valid_summary_op = tf.summary.merge(summaries)\n",
    "\n",
    "# spectr_summary_op = tf.summary.image('spectrogramm', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(tf.global_variables())\n",
    "checkpoint_path = os.path.join('trained_model/new', 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500. Training loss: 0.90963. Validation loss: 0.84211. Time: 42.06875658035278"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-404eef8f8376>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn_train_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnn_train_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step_update_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\soft\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\soft\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\soft\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\soft\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\soft\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\soft\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "options = tf.RunOptions(trace_level = tf.RunOptions.NO_TRACE)\n",
    "\n",
    "train_writer = tf.summary.FileWriter('logdir/new/train', sess.graph)\n",
    "valid_writer = tf.summary.FileWriter('logdir/new/valid')\n",
    "\n",
    "sess.run(tf.global_variables_initializer(), options=options)\n",
    "\n",
    "sess.run(train_iterator.initializer, \n",
    "         feed_dict={filenames: train_files[:, 0]}, options=options)\n",
    "\n",
    "sess.run(valid_iterator.initializer, \n",
    "         feed_dict={filenames: valid_files[:, 0]}, options=options)\n",
    "sess.graph.finalize()\n",
    "\n",
    "started = False\n",
    "for i in range(TRAINING_STEPS):\n",
    "    if not started:\n",
    "        start = time.time()\n",
    "        started = True\n",
    "        \n",
    "    _ = sess.run(cnn_train_op, options=options)\n",
    "    _ = sess.run(rnn_train_op, options=options)\n",
    "    \n",
    "    sess.run(global_step_update_op)\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        training_loss, summary  = sess.run([loss, train_summary_op], options=options)\n",
    "        train_writer.add_summary(summary, i)\n",
    "\n",
    "#         validation_loss = sess.run(loss, feed_dict={is_training: False}, options=options)\n",
    "\n",
    "        validation_loss, summary = sess.run([loss, valid_summary_op], feed_dict={is_training: False}, options=options)\n",
    "        valid_writer.add_summary(summary, i)\n",
    "\n",
    "        saver.save(sess, checkpoint_path, i)\n",
    "        \n",
    "        finish = time.time()\n",
    "        started = False\n",
    "        print('\\rStep %i. Training loss: %.5f. Validation loss: %.5f. Time: %s' % (i, training_loss, validation_loss, str(finish - start)), end='')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trained_model/new\\\\model.ckpt-499999'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, checkpoint_path, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
