{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEECH_DATA_PATH = 'D:/musan/musan/speech/librivox'\n",
    "NOISE1_DATA_PATH = 'D:/musan/musan/noise/sound-bible'\n",
    "NOISE2_DATA_PATH = 'D:/musan/musan/noise/free-sound'\n",
    "MUSIC_DATA_PATH = 'D:/musan/musan/music'\n",
    "MUSIC_FOLDERS = ['fma', 'fma-western-art', 'hd-classical', 'rfm']\n",
    "TARGET_FOLDER = 'D:/musan/preprocessed'\n",
    "\n",
    "SR = 16000\n",
    "SNR_RATES = [-10, -5, 0, 5, 10, 15, 20]\n",
    "\n",
    "CUT_OFF = 4000\n",
    "FFT_SIZE = 512\n",
    "FFT_STEP = SR / FFT_SIZE\n",
    "FRAME_SIZE = FFT_SIZE # 32ms for SR = 16kHz\n",
    "FRAME_OFFSET =  128\n",
    "VOICE_THRESHOLD = 0.0002\n",
    "\n",
    "N_HARM = 14\n",
    "N_CAND = 100\n",
    "F0_RAANGE = (70, 350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: https://arxiv.org/pdf/1510.08484.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup SNR\n",
    "\n",
    "\\begin{equation}\n",
    "SNR = 20 * log_{10}\\left(\\frac{A}{k*A_n}\\right) => k=10^{log_{10}\\left(\\frac{A}{A_n}\\right)-\\frac{SNR}{20}}\n",
    "\\end{equation}\n",
    "\n",
    "Since the signal power ($A$ and $A_n$) is a quadratic value, the coefficient $k$ also has a quadratic value. Therefore, the actual value of the coefficient $k$ for multiply the noise signal in order to obtain the given $SNR$ is calculated by the formula:\n",
    "\n",
    "\\begin{equation}\n",
    "k=10^{\\frac{log_{10}\\left(\\frac{A}{A_n}\\right)-\\frac{SNR}{20}}{2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNR(signal, noise):\n",
    "    A = np.mean(signal ** 2)\n",
    "    A_noise = np.mean(noise ** 2)\n",
    "    snr = 20 * np.log10(A / A_noise)\n",
    "    \n",
    "    return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr_coefficient(target_snr, signal, noise):\n",
    "    A = np.mean(signal ** 2)\n",
    "    A_noise = np.mean(noise ** 2)\n",
    "    \n",
    "    k = 10 ** ((np.log10(A / A_noise) - target_snr / 20) / 2)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_sig_noise(signal, noise, target_snr):\n",
    "    k = snr_coefficient(target_snr, signal, noise)\n",
    "    scaled_noise = k * noise\n",
    "    \n",
    "    if len(scaled_noise) <= len(signal):\n",
    "        n_repeats = len(signal) // len(scaled_noise) + 1\n",
    "        scaled_noise = np.tile(scaled_noise, n_repeats)\n",
    "        \n",
    "    noisy_signal = signal + scaled_noise[:len(signal)]\n",
    "    noisy_signal[noisy_signal > 1.] = 1.\n",
    "    noisy_signal[noisy_signal < -1.] = -1.\n",
    "    return noisy_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, _ = librosa.load(os.path.join(SPEECH_DATA_PATH, 'speech-librivox-0013.wav'), sr=SR)\n",
    "# ipd.Audio(y, rate=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_noise, _ = librosa.load(os.path.join(NOISE1_DATA_PATH, 'noise-sound-bible-0009.wav'), sr=SR)\n",
    "# ipd.Audio(y_noise, rate=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original SNR: -25.593, coefficient: 0.408, target SNR: -10.000\n"
     ]
    }
   ],
   "source": [
    "original_snr = SNR(y, y_noise)\n",
    "\n",
    "target_snr = -10\n",
    "\n",
    "k = snr_coefficient(target_snr, y, y_noise)\n",
    "scaled_y_noise = k * y_noise\n",
    "\n",
    "snr = SNR(y, scaled_y_noise)\n",
    "\n",
    "print('Original SNR: %.3f, coefficient: %.3f, target SNR: %.3f' % (original_snr, k, snr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_signal = mix_sig_noise(y, y_noise, target_snr)\n",
    "# ipd.Audio(noisy_signal, rate=SR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wav_files(path):\n",
    "    filenames = []\n",
    "    for f in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path, f)) and f.endswith('.wav'):\n",
    "            filenames.append(os.path.join(path, f))\n",
    "            \n",
    "    return filenames\n",
    "\n",
    "def get_file_size(path):\n",
    "    y, _ = librosa.load(path, sr=SR)\n",
    "    if y.max() > 1:\n",
    "        print(path, y.max())\n",
    "    return len(y) / SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_filenames = get_wav_files(SPEECH_DATA_PATH)\n",
    "\n",
    "noisy_filenames = get_wav_files(NOISE1_DATA_PATH)\n",
    "noisy_filenames += get_wav_files(NOISE2_DATA_PATH)\n",
    "noisy_filenames += get_wav_files(os.path.join(MUSIC_DATA_PATH, MUSIC_FOLDERS[0]))\n",
    "noisy_filenames += get_wav_files(os.path.join(MUSIC_DATA_PATH, MUSIC_FOLDERS[1]))\n",
    "noisy_filenames += get_wav_files(os.path.join(MUSIC_DATA_PATH, MUSIC_FOLDERS[2]))\n",
    "noisy_filenames += get_wav_files(os.path.join(MUSIC_DATA_PATH, MUSIC_FOLDERS[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 173 speech files with 20.4 hours of records\n",
      "Total 1373 files with noise (34.3 hours)\n"
     ]
    }
   ],
   "source": [
    "file_sizes = [get_file_size(f) for f in speech_filenames]\n",
    "total_size = sum(file_sizes)\n",
    "\n",
    "print('Total %i speech files with %.1f hours of records' % (len(speech_filenames), total_size/60/60))\n",
    "\n",
    "file_sizes = [get_file_size(f) for f in noisy_filenames]\n",
    "total_size = sum(file_sizes)\n",
    "\n",
    "print('Total %i files with noise (%.1f hours)' % (len(noisy_filenames), total_size/60/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(signal):\n",
    "    grid_smp = np.arange(0, signal.shape[0] - FRAME_SIZE, FRAME_OFFSET)\n",
    "    frames = np.zeros(shape=(grid_smp.shape[0], FRAME_SIZE))\n",
    "    \n",
    "    for i in range(grid_smp.shape[0]):\n",
    "        l_i = grid_smp[i]\n",
    "        r_i = l_i + FRAME_SIZE\n",
    "        frames[i, :] = signal[l_i:r_i]\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectr(frames):\n",
    "    window = np.hamming(frames.shape[1])\n",
    "    window = np.reshape(window, (1, frames.shape[1]))\n",
    "    weighted_frames = frames * window\n",
    "    \n",
    "    spectr = np.fft.fft(weighted_frames, n=FFT_SIZE, axis=1)\n",
    "    spectr = spectr / FFT_SIZE * 2\n",
    "    spectr_log = np.log10(abs(spectr)) \n",
    "    \n",
    "    n_env = int(CUT_OFF // FFT_STEP)\n",
    "    spectr_log = spectr_log[:, :n_env]\n",
    "    \n",
    "    return spectr_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_harmonics(spectr):\n",
    "    fft_inds = np.zeros(shape=(N_HARM, N_CAND), dtype=np.int32)\n",
    "    cands = np.linspace(F0_RAANGE[0], F0_RAANGE[1], N_CAND)\n",
    "    \n",
    "    for i in range(N_CAND):\n",
    "        indices = np.round((1 + np.arange(0, N_HARM)) / 2 * cands[i] / FFT_STEP + 1)\n",
    "        fft_inds[:, i] = indices.astype(np.int32)\n",
    "\n",
    "    features = spectr[:, fft_inds]\n",
    "    features = np.transpose(features, axes=(0, 2, 1))\n",
    "#     features = features[..., np.newaxis]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(signal):\n",
    "    frames = get_frames(signal)\n",
    "    spectr = get_spectr(frames)\n",
    "    features = get_harmonics(spectr)\n",
    "    \n",
    "    return features.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(signal):\n",
    "    frames = get_frames(signal)\n",
    "    frames = np.mean(frames ** 2, axis=1)\n",
    "    labels = (frames > VOICE_THRESHOLD).astype(np.float32)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173\r"
     ]
    }
   ],
   "source": [
    "# dataset = []\n",
    "\n",
    "for i, speech_filename in enumerate(speech_filenames):\n",
    "    print('%i/%i' % (i+1, len(speech_filenames)), end='\\r', flush=True)\n",
    "    signal, _ = librosa.load(speech_filename, sr=SR)\n",
    "    \n",
    "    noise_filename = np.random.choice(noisy_filenames)\n",
    "    noise, _ = librosa.load(noise_filename, sr=SR)\n",
    "    \n",
    "    target_snr = np.random.choice(SNR_RATES)\n",
    "    noisy_signal = mix_sig_noise(signal, noise, target_snr)\n",
    "    \n",
    "    features = get_features(noisy_signal)\n",
    "    labels = get_labels(signal)\n",
    "        \n",
    "    target_filename = os.path.join(TARGET_FOLDER, os.path.basename(speech_filename))\n",
    "    np.savez(target_filename, features=features, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
